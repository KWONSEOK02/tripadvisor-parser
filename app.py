import streamlit as st
import pandas as pd
import json
import google.generativeai as genai
import io
import base64
import prompts
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Any, Dict, List

# --- [ë‚´ë¶€ ë¡œì§: ì‚¬ìš©ìì—ê²Œ ìˆ¨ê²¨ì§„ ìë™ ì„¤ì •ê°’ë“¤] ---
DEFAULT_URL_KEYWORD = "/data/graphql/ids"
DEFAULT_PREPROCESS_MODE = "response_text_compact_graphql_ids"

# -----------------------------
# HAR ì „ì²˜ë¦¬ ìœ í‹¸ (ë‚´ë¶€ ìë™í™”)
# -----------------------------
def iter_har_entries(har_data: Dict[str, Any]) -> List[Dict[str, Any]]:
    return har_data.get("log", {}).get("entries", []) or []

def safe_get(d: Any, path: List[Any], default=None):
    cur = d
    for p in path:
        try:
            if isinstance(cur, dict) and p in cur:
                cur = cur[p]
            elif isinstance(cur, list) and isinstance(p, int) and 0 <= p < len(cur):
                cur = cur[p]
            else:
                return default
        except Exception:
            return default
    return cur

def extract_response_text(entry: Dict[str, Any]) -> str:
    text = safe_get(entry, ["response", "content", "text"], "") or ""
    encoding = (safe_get(entry, ["response", "content", "encoding"], "") or "").lower()
    if encoding == "base64":
        try:
            return base64.b64decode(text).decode("utf-8", errors="replace")
        except Exception:
            return text
    return text

def looks_like_owner_metrics_payload(resp_text: str) -> bool:
    keywords = ["RsOwnerMetrics_", "metricType", "groupDimensionValue", "LISTING_IMPRESSION_COUNT"]
    return any(k in resp_text for k in keywords)

def compact_tripadvisor_graphql_ids_response(resp_text: str) -> str:
    try:
        payload = json.loads(resp_text)
        if not isinstance(payload, list):
            return resp_text
        compact = []
        for item in payload:
            if not isinstance(item, dict):
                continue
            data_obj = item.get("data")
            if not isinstance(data_obj, dict):
                continue
            owner_keys = [k for k in data_obj.keys() if str(k).startswith("RsOwnerMetrics_")]
            if owner_keys:
                compact.append({"data": {k: data_obj.get(k) for k in owner_keys}})
        return json.dumps(compact, ensure_ascii=False, separators=(",", ":")) if compact else resp_text
    except Exception:
        return resp_text

# -----------------------------
# í•µì‹¬ ìë™ ì²˜ë¦¬ í•¨ìˆ˜ (Zero-Config + Fallback)
# -----------------------------
def auto_smart_filter(har_data: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Zero-Config ìë™ íƒìƒ‰:
    1ìˆœìœ„: URLì— /data/graphql/ids í¬í•¨
    2ìˆœìœ„: URLì— graphql í¬í•¨
    3ìˆœìœ„: ì‘ë‹µ ë³¸ë¬¸ì— RsOwnerMetrics_ í¬í•¨
    ê³µí†µ ì¡°ê±´: 2xx + JSON mime + (ì§€í‘œë¡œ ë³´ì´ëŠ” payload)
    """
    entries = iter_har_entries(har_data)

    def base_conditions(entry: Dict[str, Any]) -> bool:
        status = safe_get(entry, ["response", "status"], 0) or 0
        mime = (safe_get(entry, ["response", "content", "mimeType"], "") or "").lower()
        return (200 <= int(status) < 300) and ("json" in mime)

    def is_metrics_entry(entry: Dict[str, Any]) -> bool:
        resp_text = extract_response_text(entry)
        return bool(resp_text) and looks_like_owner_metrics_payload(resp_text)

    # --- 1ìˆœìœ„: /data/graphql/ids ---
    out_1 = []
    for entry in entries:
        url = (safe_get(entry, ["request", "url"], "") or "")
        if base_conditions(entry) and (DEFAULT_URL_KEYWORD in url) and is_metrics_entry(entry):
            out_1.append(entry)
    if out_1:
        return out_1

    # --- 2ìˆœìœ„: URLì— graphql í¬í•¨ ---
    out_2 = []
    for entry in entries:
        url = (safe_get(entry, ["request", "url"], "") or "").lower()
        if base_conditions(entry) and ("graphql" in url) and is_metrics_entry(entry):
            out_2.append(entry)
    if out_2:
        return out_2

    # --- 3ìˆœìœ„: ì‘ë‹µ ë³¸ë¬¸ì— RsOwnerMetrics_ í¬í•¨ (URL ë¬´ê´€) ---
    out_3 = []
    for entry in entries:
        if base_conditions(entry):
            resp_text = extract_response_text(entry)
            if "RsOwnerMetrics_" in (resp_text or "") and is_metrics_entry(entry):
                out_3.append(entry)
    return out_3

#------------------
# JSON ë°°ì—´ë§Œ ì¶”ì¶œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜
#------------------
def extract_json_array(text: str) -> str:
    """
    Gemini ì‘ë‹µì—ì„œ ì²« '[' ì™€ ë§ˆì§€ë§‰ ']' ì‚¬ì´ë§Œ ì˜ë¼ëƒ„
    """
    if not text:
        return ""
    start = text.find("[")
    end = text.rfind("]")
    if start == -1 or end == -1 or end <= start:
        return ""
    return text[start : end + 1]

# -----------------------------
# Gemini í˜¸ì¶œ ë¡œì§ (ë³‘ë ¬ ì²˜ë¦¬)
# -----------------------------
def process_chunk(index: int, chunk: str, hotel_name: str, api_key: str):
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel("gemini-2.5-flash")
    prompt = prompts.get_extraction_prompt(hotel_name, chunk)

    for attempt in range(3):  # ìµœì´ˆ 1íšŒ + ì¬ì‹œë„ 2íšŒ
        try:
            response = model.generate_content(prompt)

            # 1) ì½”ë“œë¸”ë¡ ì œê±°
            text = (
                response.text
                .replace("```json", "")
                .replace("```", "")
                .strip()
            )

            # 2) JSON ë°°ì—´ë§Œ ì¶”ì¶œ
            json_text = extract_json_array(text)
            if not json_text:
                raise ValueError("JSON array not found")

            # 3) íŒŒì‹±
            parsed = json.loads(json_text)

            if isinstance(parsed, list):
                return parsed
            elif isinstance(parsed, dict):
                return [parsed]
            else:
                raise ValueError("Parsed JSON is not list/dict")

        except Exception:
            # ë§ˆì§€ë§‰ ì‹œë„ë©´ í¬ê¸°
            if attempt == 2:
                return []
            continue


# -----------------------------
# Streamlit UI (ì´ˆê°„ë‹¨ ë²„ì „)
# -----------------------------
st.set_page_config(page_title="íŠ¸ë¦½ì–´ë“œë°”ì´ì € ë°ì´í„° ìë™ ë³€í™˜ê¸°", layout="centered")
st.title("ğŸ¨ íŠ¸ë¦½ì–´ë“œë°”ì´ì € ë¦¬í¬íŠ¸ ìë™ ìƒì„±ê¸°")
st.markdown("HAR íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì§€ì ëª…ë§Œ ì…ë ¥í•˜ë©´ AIê°€ ë³´ê³ ì„œë¥¼ ë§Œë“¤ì–´ ë“œë¦½ë‹ˆë‹¤.")

# API í‚¤ ìë™ ë¡œë“œ
api_keys = [st.secrets[k] for k in ["GEMINI_API_KEY_1", "GEMINI_API_KEY_2"] if k in st.secrets]

# API í‚¤ê°€ ì—†ìœ¼ë©´ ì•ˆë‚´ í›„ ì¤‘ë‹¨
if not api_keys:
    st.error("âŒ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. Streamlit secretsì— GEMINI_API_KEY_1 (ë° ì„ íƒìœ¼ë¡œ GEMINI_API_KEY_2)ë¥¼ ì¶”ê°€í•´ ì£¼ì„¸ìš”.")
    st.stop()

with st.container(border=True):
    uploaded_file = st.file_uploader("1. HAR íŒŒì¼ì„ ë“œë˜ê·¸í•´ì„œ ë†“ìœ¼ì„¸ìš”", type=["har"])
    hotel_name_input = st.text_input("2. ì§€ì ëª…ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: íŠ¸ë¦½ì–´ë“œë°”ì´ì € ì„œìš¸ì ")

with st.expander("ê³ ê¸‰ ì •ë³´(ì„ íƒ)"):
    st.markdown(
        """
**í˜„ì¬ ìë™ í•„í„° (Zero-Config)**  
- 1ìˆœìœ„: `/data/graphql/ids` + (2xx) + (JSON) + (ì§€í‘œ í‚¤ì›Œë“œ)  
- 2ìˆœìœ„: URLì— `graphql` í¬í•¨ + (2xx) + (JSON) + (ì§€í‘œ í‚¤ì›Œë“œ)  
- 3ìˆœìœ„: ì‘ë‹µ ë³¸ë¬¸ì— `RsOwnerMetrics_` í¬í•¨ + (2xx) + (JSON)  

**ì „ì²˜ë¦¬(í† í° ì ˆê°)**  
- HAR ì „ì²´ê°€ ì•„ë‹ˆë¼ `response.content.text`(ì‘ë‹µ ë³¸ë¬¸)ë§Œ ì‚¬ìš©  
- `RsOwnerMetrics_*` ë°ì´í„°ë§Œ ë‚¨ê¸°ë„ë¡ ì••ì¶•(ê°€ëŠ¥í•œ ê²½ìš°)  
        """
    )

if uploaded_file and hotel_name_input:
    st.caption("ìë™ìœ¼ë¡œ íŠ¸ë¦½ì–´ë“œë°”ì´ì € ì§€í‘œ ì‘ë‹µì„ ì°¾ì•„ ì••ì¶• í›„ ë¶„ì„í•©ë‹ˆë‹¤.")
    if st.button("ğŸš€ ë¶„ì„ ì‹œì‘ (ì•½ 1ë¶„ ì†Œìš”)", width='stretch', type="primary"):
        with st.status("ë°ì´í„° ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„± ì¤‘...", expanded=True) as status:
            har_data = json.load(uploaded_file)

            # [ìë™ ì²˜ë¦¬ 1] ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ (Fallback í¬í•¨)
            st.write("ğŸ” ë°ì´í„° ìœ„ì¹˜ ì°¾ëŠ” ì¤‘...")
            filtered = auto_smart_filter(har_data)

            if not filtered:
                st.error("ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ HAR íŒŒì¼ì¸ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")
                st.stop()

            # [ìë™ ì²˜ë¦¬ 2] ì „ì²˜ë¦¬ ë° ì••ì¶•
            st.write(f"ğŸ“¦ ë°ì´í„° ì••ì¶• ë° ìµœì í™” ì¤‘... (ë°œê²¬ëœ í•­ëª©: {len(filtered)}ê°œ)")
            parts = []
            for entry in filtered:
                txt = extract_response_text(entry)
                parts.append(compact_tripadvisor_graphql_ids_response(txt))
            full_text = "\n\n-----\n\n".join(parts)

            # [ìë™ ì²˜ë¦¬ 3] ë¶„í•  ë° ë³‘ë ¬ AI ë¶„ì„
            st.write("ğŸ¤– AI ì§€í‘œ ì¶”ì¶œ ì¤‘ (ë³‘ë ¬ ì—”ì§„ ê°€ë™)...")
            chunks = [full_text[i : i + 40000] for i in range(0, len(full_text), 40000)]
            all_data: List[Dict[str, Any]] = []

            max_workers = max(1, len(api_keys))
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = [
                    executor.submit(
                        process_chunk,
                        i,
                        chunk,
                        hotel_name_input,
                        api_keys[i % len(api_keys)],
                    )
                    for i, chunk in enumerate(chunks)
                ]
                for future in as_completed(futures):
                    all_data.extend(future.result())

            status.update(label="âœ… ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)

        # ê²°ê³¼ ì •ë¦¬ ë° ì¶œë ¥
        if all_data:
            df = pd.DataFrame(all_data)
            if "ì¼ì" in df.columns:
                df["ì¼ì"] = pd.to_datetime(df["ì¼ì"], errors="coerce").dt.strftime("%Y-%m-%d")
                df = df.dropna(subset=["ì¼ì"]).drop_duplicates(subset=["ì¼ì"]).sort_values(by="ì¼ì")
            df["ì§€ì ëª…"] = hotel_name_input
            df = df.fillna(0)

            st.balloons()
            if "ì¼ì" in df.columns and not df.empty:
                st.success(f"ì´ {len(df)}ì¼ì¹˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤! ({df['ì¼ì'].min()} ~ {df['ì¼ì'].max()})")
            else:
                st.success(f"ì´ {len(df)}ê±´ ë°ì´í„°ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤!")

            st.subheader("ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìµœê·¼ 5ì¼)")
            st.dataframe(df.head(5), use_container_width=True)

            # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                df.to_excel(writer, index=False)

            st.download_button(
                label="ğŸ“¥ ì—‘ì…€ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
                data=output.getvalue(),
                file_name=f"TripAdvisor_Report_{hotel_name_input}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
            )
        else:
            st.error("âš ï¸ AIê°€ ìœ íš¨í•œ ë°ì´í„°ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. HAR íŒŒì¼ ë˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
