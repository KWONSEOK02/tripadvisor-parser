import streamlit as st
import pandas as pd
import json
import io
from datetime import datetime

# 1. ì§€í‘œëª… ë§¤í•‘ (ì‚¬ìš©ì ìš”ì²­: ê´„í˜¸ ë°–ì˜ ì´ë¦„ìœ¼ë¡œ ë³€ê²½)
COLUMN_MAP = {
    'LISTING_IMPRESSION_COUNT': 'Listing impressions',
    'UNIQUE_VISIT_COUNT': 'Unique page views',
    'BUBBLE_RATING': 'Average bubble rating',
    'RANKING': 'Average ranking',
    'HOTEL_REFERRAL_CLICK_COUNT': 'Direct referrals',
    'HOTEL_BOOKINGS_CLICK_COUNT': 'Booking clicks',
    'REVIEW_COUNT': 'New reviews',
    'HOTEL_SEARCH_TRIP_LENGTH_AVERAGE': 'Average booking length',
    'HOTEL_SEARCH_LEAD_TIME_AVERAGE': 'Average booking lead time'
}

# 2. ìµœì¢… ì»¬ëŸ¼ ìˆœì„œ ì„¤ì •
FINAL_ORDER = ['ì¼ì', 'ì§€ì ëª…'] + list(COLUMN_MAP.values())

st.set_page_config(page_title="íŠ¸ë¦½ì–´ë“œë°”ì´ì € ì‹¤ì  ë¶„ì„ê¸°", layout="wide")

st.title("ğŸ“Š íŠ¸ë¦½ì–´ë“œë°”ì´ì € ì‹¤ì  ë°ì´í„° ë³€í™˜ ë„êµ¬")
st.info("HAR íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ ìš”ì²­í•˜ì‹  í˜•ì‹ìœ¼ë¡œ ì •ë ¬ ë° ë³€í™˜í•©ë‹ˆë‹¤.")

uploaded_file = st.file_uploader("HAR íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['har'])

if uploaded_file is not None:
    try:
        har_data = json.load(uploaded_file)
        all_rows = []
        
        # HAR íŒŒì¼ì˜ entries ìˆœíšŒ
        for entry in har_data.get('log', {}).get('entries', []):
            # ì‘ë‹µ ë³¸ë¬¸ í™•ì¸
            response_text = entry.get('response', {}).get('content', {}).get('text', '')
            if not response_text:
                continue
                
            try:
                data_json = json.loads(response_text)
                
                # 'EventResponses'ê°€ ìˆê³  ë°ì´í„°ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš° íƒìƒ‰
                if isinstance(data_json, dict) and data_json.get('EventResponses'):
                    events = data_json['EventResponses']
                    
                    # ì§€ì ëª… ì¶”ì¶œ: íŒŒì¼ ë‚´ locationIdë‚˜ ë‹¤ë¥¸ ì •ë³´ë¥¼ í™œìš©
                    # HAR ë‚´ URLì—ì„œ locationId ì¶”ì¶œ ì‹œë„
                    url = entry.get('request', {}).get('url', '')
                    loc_id = "Unknown"
                    if "locationId=" in url:
                        loc_id = url.split("locationId=")[1].split("&")[0]

                    for event in events:
                        # ë‚ ì§œ ì •ë³´ (Date í˜¹ì€ date í‚¤ í™•ì¸)
                        raw_date = event.get('Date') or event.get('date')
                        if not raw_date:
                            continue
                            
                        # í–‰ ë°ì´í„° ìƒì„±
                        row = {
                            'ì¼ì': raw_date,
                            'ì§€ì ëª…': loc_id  # íŒŒì¼ì— ëª…í™•í•œ ì´ë¦„ì´ ì—†ìœ¼ë©´ IDë¡œ í‘œì‹œ
                        }
                        
                        # ì§€í‘œ ë§¤í•‘ (Metrics ê°ì²´ ì•ˆì— ìˆê±°ë‚˜ í‰ë©´ êµ¬ì¡°ì¼ ê²½ìš° ëª¨ë‘ ëŒ€ì‘)
                        metrics_source = event.get('Metrics', event)
                        for raw_key, friendly_name in COLUMN_MAP.items():
                            row[friendly_name] = metrics_source.get(raw_key, 0)
                        
                        all_rows.append(row)
            except json.JSONDecodeError:
                continue

        if all_rows:
            df = pd.DataFrame(all_rows)
            
            # 1. ì¼ì í˜•ì‹ ì •ë¦¬ (ISO í˜•ì‹ì„ YYYY-MM-DDë¡œ)
            df['ì¼ì'] = pd.to_datetime(df['ì¼ì']).dt.strftime('%Y-%m-%d')
            
            # 2. ì¤‘ë³µ ì œê±° (ì—¬ëŸ¬ API í˜¸ì¶œì—ì„œ ê²¹ì¹˜ëŠ” ë°ì´í„° ì œê±°)
            df = df.drop_duplicates(subset=['ì¼ì', 'ì§€ì ëª…'])
            
            # 3. ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ (ë‚ ì§œ ê¸°ì¤€)
            df = df.sort_values(by='ì¼ì', ascending=True)

            # 4. ì»¬ëŸ¼ ìˆœì„œ ê³ ì • ë° ì—†ëŠ” ì»¬ëŸ¼ ìƒì„± (0ìœ¼ë¡œ ì±„ì›€)
            for col in FINAL_ORDER:
                if col not in df.columns:
                    df[col] = 0
            
            df = df[FINAL_ORDER]

            # ê²°ê³¼ ì¶œë ¥
            st.success(f"âœ… ì´ {len(df)}ì¼ì¹˜ì˜ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
            st.dataframe(df, use_container_width=True)

            # ì—‘ì…€ ë³€í™˜
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                df.to_excel(writer, index=False, sheet_name='Report')
                
                # ì„œì‹ ì§€ì •
                workbook = writer.book
                worksheet = writer.sheets['Report']
                header_format = workbook.add_format({'bold': True, 'bg_color': '#D9EAD3', 'border': 1})
                for col_num, value in enumerate(df.columns.values):
                    worksheet.write(0, col_num, value, header_format)

            st.download_button(
                label="ğŸ“¥ ë³€í™˜ëœ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                data=output.getvalue(),
                file_name=f"Tripadvisor_Report_{datetime.now().strftime('%Y%m%d')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        else:
            st.error("âš ï¸ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: ì—…ë¡œë“œí•œ HAR íŒŒì¼ì— ìœ íš¨í•œ ì‹¤ì  ë°ì´í„°(EventResponses)ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. íŠ¸ë¦½ì–´ë“œë°”ì´ì € í˜ì´ì§€ì—ì„œ ì°¨íŠ¸ê°€ ë¡œë“œëœ ê²ƒì„ í™•ì¸í•œ í›„ ë‹¤ì‹œ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.")

    except Exception as e:
        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")